{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "heackerton_ictcoc.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ4tYc2H8vbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n-inYqD9Gsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.set_random_seed(777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYykmRvl9Iyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reverse_min_max_scaling(org_x, x):\n",
        "    org_x_np = np.asarray(org_x)\n",
        "    x_np = np.asarray(x)\n",
        "    return (x_np * (org_x_np.max() - org_x_np.min() + 1e-7)) + org_x_np.min()\n",
        "\n",
        "def MinMaxScaler(data):\n",
        "    numerator = data - np.min(data, 0)\n",
        "    denominator = np.max(data, 0) - np.min(data, 0)\n",
        "    # noise term prevents the zero division\n",
        "    return numerator / (denominator + 1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzZZ9y6Z9KAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "aaf4f52e-099e-4a23-a5f2-c85b482b0e08"
      },
      "source": [
        "file_name = 'product.csv' # 데이터셋 이름 입력\n",
        "colums = ['avg_1', 'avg_2', 'avg_3', 'min_1', 'min_2', 'min_3', 'max_1', 'max_2', 'max_3', 'rain_1', 'rain_2', 'rain_3', 'Product']\n",
        "raw_dataframe = pd.read_csv(file_name, names=colums) # pandas의 Dataframe 형식으로 csv 를 읽음\n",
        "raw_dataframe.info()\n",
        "\n",
        "product_info = raw_dataframe.values[1:].astype(np.float)\n",
        "print('info.shape : ', product_info.shape)\n",
        "print('info[0] : ', product_info[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 272 entries, 0 to 271\n",
            "Data columns (total 13 columns):\n",
            "avg_1      272 non-null float64\n",
            "avg_2      272 non-null float64\n",
            "avg_3      272 non-null float64\n",
            "min_1      272 non-null float64\n",
            "min_2      272 non-null float64\n",
            "min_3      272 non-null float64\n",
            "max_1      272 non-null float64\n",
            "max_2      272 non-null float64\n",
            "max_3      272 non-null float64\n",
            "rain_1     272 non-null float64\n",
            "rain_2     272 non-null float64\n",
            "rain_3     272 non-null float64\n",
            "Product    272 non-null float64\n",
            "dtypes: float64(13)\n",
            "memory usage: 27.7 KB\n",
            "info.shape :  (271, 13)\n",
            "info[0] :  [1.010e+01 1.360e+01 2.120e+01 4.300e+00 9.500e+00 1.590e+01 1.580e+01\n",
            " 1.840e+01 2.700e+01 5.000e-01 1.600e+00 1.200e+00 3.839e+03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3wg-lwP9Ov4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data_colums_count = len(product_info[0])\n",
        "output_data_colums_count = 1\n",
        "\n",
        "seq_length = 16\n",
        "rnn_cell_hidden_dim = 20\n",
        "forget_bias = 1.0\n",
        "num_stacked_layers = 1\n",
        "keep_prob = 1.0\n",
        "\n",
        "epoch_num = 50000\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3AiTzAX9Q7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "616f9180-ebfc-4bd0-ba72-371c56602e6f"
      },
      "source": [
        "temp_rain_data = product_info[:, :-1]\n",
        "norm_temp_rain = MinMaxScaler(temp_rain_data)\n",
        "print('temp_rain.shape : ', temp_rain_data.shape)\n",
        "print('temp_rain[0] : ', temp_rain_data[0])\n",
        "print('norm_temp_rain[0] : ', norm_temp_rain[0])\n",
        "print('='*30)\n",
        "\n",
        "\n",
        "product_num = product_info[:, -1:]\n",
        "norm_product_num = MinMaxScaler(product_num)\n",
        "print('product_num.shape : ', product_num.shape)\n",
        "print('product_num[0] : ', product_num[0])\n",
        "print('norm_product_num[0] : ', norm_product_num[0])\n",
        "print('='*30)\n",
        "\n",
        "x = np.concatenate((norm_temp_rain, norm_product_num), axis=1)\n",
        "print('x.shape : ', x.shape)\n",
        "print('x[0] : ', x[0])\n",
        "print('x[-1] : ', x[-1])\n",
        "print('='*30)\n",
        "\n",
        "y = x[:, [-2]]\n",
        "print('y[0] : ', y[0])\n",
        "print('y[-1] : ', y[-1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "temp_rain.shape :  (271, 12)\n",
            "temp_rain[0] :  [10.1 13.6 21.2  4.3  9.5 15.9 15.8 18.4 27.   0.5  1.6  1.2]\n",
            "norm_temp_rain[0] :  [0.63013612 0.18333303 0.55319031 0.58252371 0.52272668 0.5781241\n",
            " 0.635416   0.20731682 0.63013612 0.06249992 0.09420283 0.10810801]\n",
            "==============================\n",
            "product_num.shape :  (271, 1)\n",
            "product_num[0] :  [3839.]\n",
            "norm_product_num[0] :  [0.36691198]\n",
            "==============================\n",
            "x.shape :  (271, 13)\n",
            "x[0] :  [0.63013612 0.18333303 0.55319031 0.58252371 0.52272668 0.5781241\n",
            " 0.635416   0.20731682 0.63013612 0.06249992 0.09420283 0.10810801\n",
            " 0.36691198]\n",
            "x[-1] :  [0.76712224 0.78333203 0.55319031 0.79611573 0.84090814 0.640624\n",
            " 0.7083326  0.6951211  0.6027389  0.6374992  0.21739115 0.12612601\n",
            " 0.45512759]\n",
            "==============================\n",
            "y[0] :  [0.10810801]\n",
            "y[-1] :  [0.12612601]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Ihyvnr9S28",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "outputId": "64c2d7bd-8d18-4a14-beec-89c17eebe30c"
      },
      "source": [
        "dataX = []\n",
        "dataY = []\n",
        "\n",
        "for i in range(0, len(y) - seq_length):\n",
        "    _x = x[i : i + seq_length]\n",
        "    _y = y[i + seq_length]\n",
        "    if i is 0:\n",
        "        print(_x, '->', _y)\n",
        "    dataX.append(_x)\n",
        "    dataY.append(_y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.63013612 0.18333303 0.55319031 0.58252371 0.52272668 0.5781241\n",
            "  0.635416   0.20731682 0.63013612 0.06249992 0.09420283 0.10810801\n",
            "  0.36691198]\n",
            " [0.45205418 0.33333278 0.65957306 0.57281498 0.56818117 0.71874888\n",
            "  0.43749954 0.341463   0.68493057 0.02499997 0.1014492  0.12612601\n",
            "  0.35305362]\n",
            " [0.38356112 0.23333294 0.34042481 0.61164989 0.62499929 0.67187395\n",
            "  0.36458295 0.24390214 0.41095834 0.02499997 0.11594194 0.06306301\n",
            "  0.41250119]\n",
            " [0.41095834 0.31666614 0.44680756 0.35922295 0.46590856 0.51562419\n",
            "  0.60416604 0.46341407 0.6027389  0.11249986 0.13768106 0.24324302\n",
            "  0.44920195]\n",
            " [0.36986251 0.18333303 0.23404206 0.57281498 0.56818117 0.67187395\n",
            "  0.38541627 0.18292661 0.246575   0.04999994 0.07246372 0.43243204\n",
            "  0.36777215]\n",
            " [0.63013612 0.53333244 0.87233857 0.62135862 0.69318103 0.82812371\n",
            "  0.635416   0.5121945  0.80821807 0.09999988 0.08695646 0.14414401\n",
            "  0.45866386]\n",
            " [0.7260264  0.44999925 0.46808411 0.66990226 0.67045378 0.62499902\n",
            "  0.7083326  0.45121896 0.57534168 0.19999975 0.14492743 0.09009001\n",
            "  0.42148523]\n",
            " [0.52054723 0.38333269 0.55319031 0.45631024 0.47727218 0.60937405\n",
            "  0.67708263 0.60975535 0.71232779 0.07499991 0.06521734 0.18018002\n",
            "  0.48647615]\n",
            " [0.73972501 0.38333269 0.25531861 0.82524192 0.76136277 0.65624897\n",
            "  0.635416   0.28048746 0.27397223 0.18749977 0.12318832 0.17117102\n",
            "  0.42492593]\n",
            " [0.26027362 0.11666647 0.38297791 0.26213567 0.30681783 0.40624937\n",
            "  0.45833286 0.341463   0.64383473 0.04999994 0.13043469 0.06306301\n",
            "  0.35658989]\n",
            " [0.23287639 0.16666639 0.29787171 0.07766983 0.22727247 0.28124956\n",
            "  0.58333273 0.46341407 0.6027389  0.12499984 0.1014492  0.15315302\n",
            "  0.50320176]\n",
            " [0.13698611 0.08333319 0.34042481 0.         0.13636348 0.23437463\n",
            "  0.52083279 0.42682875 0.67123196 0.09999988 0.13768106 0.24324302\n",
            "  0.38335086]\n",
            " [0.50684862 0.31666614 0.27659516 0.42718405 0.32954508 0.39062439\n",
            "  0.60416604 0.47560918 0.45205418 0.13749983 0.05797097 0.18018002\n",
            "  0.4893434 ]\n",
            " [0.54794445 0.48333253 0.70212617 0.34951422 0.46590856 0.53124917\n",
            "  0.74999922 0.6951211  0.86301252 0.11249986 0.1014492  0.14414401\n",
            "  0.38994552]\n",
            " [0.58904029 0.26666622 0.27659516 0.57281498 0.47727218 0.45312429\n",
            "  0.58333273 0.32926789 0.41095834 0.28749964 0.10869557 0.17117102\n",
            "  0.35486954]\n",
            " [0.15068473 0.36666606 0.55319031 0.12621347 0.27272696 0.51562419\n",
            "  0.43749954 0.74390153 0.84931391 0.02499997 0.         0.34234203\n",
            "  0.41250119]] -> [0.21621602]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp3fBFKQ9Ujg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "27f7203d-f661-4ae4-a4c0-ff7bf5e28768"
      },
      "source": [
        "# train/test set 나누기\n",
        "train_size = int(len(dataY) * 0.7)  # train size = 70%\n",
        "test_size = len(dataY) - train_size\n",
        "\n",
        "trainX, testX = np.array(dataX[0:train_size]), np.array(dataX[train_size:len(dataX)])\n",
        "trainY, testY = np.array(dataY[0:train_size]), np.array(dataY[train_size:len(dataY)])\n",
        "\n",
        "# input placeholders\n",
        "X = tf.placeholder(tf.float32, [None, seq_length, input_data_colums_count])\n",
        "print('X: ', X)\n",
        "Y = tf.placeholder(tf.float32, [None, 1])\n",
        "print('Y: ', Y)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X:  Tensor(\"Placeholder:0\", shape=(?, 16, 13), dtype=float32)\n",
            "Y:  Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHaou8AF9WOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "431e2e7f-9b30-4e3a-94e9-fea8efa5d66e"
      },
      "source": [
        "# 검증용 측정지표를 산출하기 위한 targets, predictions를 생성한다\n",
        "targets = tf.placeholder(tf.float32, [None, 1])\n",
        "print(\"targets: \", targets)\n",
        " \n",
        "predictions = tf.placeholder(tf.float32, [None, 1])\n",
        "print(\"predictions: \", predictions)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "targets:  Tensor(\"Placeholder_2:0\", shape=(?, 1), dtype=float32)\n",
            "predictions:  Tensor(\"Placeholder_3:0\", shape=(?, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA4CJ6oN9X00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델(LSTM 네트워크) 생성\n",
        "def lstm_cell():\n",
        "    # LSTM셀을 생성\n",
        "    # num_units: 각 Cell 출력 크기\n",
        "    # forget_bias:  to the biases of the forget gate \n",
        "    #              (default: 1)  in order to reduce the scale of forgetting in the beginning of the training.\n",
        "    # state_is_tuple: True ==> accepted and returned states are 2-tuples of the c_state and m_state.\n",
        "    # state_is_tuple: False ==> they are concatenated along the column axis.\n",
        "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim, \n",
        "                                        forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
        "    if keep_prob < 1.0:\n",
        "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
        "    return cell"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFqR-LNV9ZRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "f30d10c3-e60c-49b5-c394-70a0a5513b16"
      },
      "source": [
        "# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\n",
        "stackedRNNs = [lstm_cell() for _ in range(num_stacked_layers)]\n",
        "multi_cells = tf.contrib.rnn.MultiRNNCell(stackedRNNs, state_is_tuple=True) if num_stacked_layers > 1 else lstm_cell()\n",
        " \n",
        "# RNN Cell(여기서는 LSTM셀임)들을 연결\n",
        "hypothesis, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
        "print(\"hypothesis: \", hypothesis)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0831 00:43:35.020349 139735493068672 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0831 00:43:35.021906 139735493068672 deprecation.py:323] From <ipython-input-10-2c54955f6881>:9: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0831 00:43:35.024154 139735493068672 deprecation.py:323] From <ipython-input-11-c9b4539491e5>:5: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "W0831 00:43:35.105688 139735493068672 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0831 00:43:35.115014 139735493068672 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "hypothesis:  Tensor(\"rnn/transpose_1:0\", shape=(?, 16, 20), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD_EWx5C9bHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [:, -1]를 잘 살펴보자. LSTM RNN의 마지막 (hidden)출력만을 사용했다.\n",
        "hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], output_data_colums_count, activation_fn=tf.identity)\n",
        " \n",
        " \n",
        "# 손실함수로 평균제곱오차를 사용한다\n",
        "loss = tf.reduce_sum(tf.square(hypothesis - Y))\n",
        "# 최적화함수로 AdamOptimizer를 사용한다\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        " \n",
        "train = optimizer.minimize(loss)\n",
        " \n",
        "# RMSE(Root Mean Square Error)\n",
        "# 제곱오차의 평균을 구하고 다시 제곱근을 구하면 평균 오차가 나온다\n",
        "# rmse = tf.sqrt(tf.reduce_mean(tf.square(targets-predictions))) # 아래 코드와 같다\n",
        "rmse = tf.sqrt(tf.reduce_mean(tf.squared_difference(targets, predictions)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81ahUm0L9dgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_error_summary = [] # 학습용 데이터의 오류를 중간 중간 기록한다\n",
        "test_error_summary = []  # 테스트용 데이터의 오류를 중간 중간 기록한다\n",
        "test_predict = ''        # 테스트용데이터로 예측한 결과\n",
        " \n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHLy2tvC9gEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dab45396-e8b0-4c52-df3d-eaf284714e1e"
      },
      "source": [
        "# 학습한다\n",
        "start_time = datetime.datetime.now() # 시작시간을 기록한다\n",
        "print('학습을 시작합니다...')\n",
        "for epoch in range(epoch_num):\n",
        "    _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
        "    if ((epoch+1) % 100 == 0) or (epoch == epoch_num-1): # 100번째마다 또는 마지막 epoch인 경우\n",
        "        # 학습용데이터로 rmse오차를 구한다\n",
        "        train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
        "        train_error = sess.run(rmse, feed_dict={targets: trainY, predictions: train_predict})\n",
        "        train_error_summary.append(train_error)\n",
        " \n",
        "        # 테스트용데이터로 rmse오차를 구한다\n",
        "        test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
        "        test_error = sess.run(rmse, feed_dict={targets: testY, predictions: test_predict})\n",
        "        test_error_summary.append(test_error)\n",
        "        \n",
        "        # 현재 오류를 출력한다\n",
        "        print(\"epoch: {}, train_error(A): {}, test_error(B): {}, B-A: {}\".format(epoch+1, train_error, test_error, test_error-train_error))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습을 시작합니다...\n",
            "epoch: 100, train_error(A): 0.13331085443496704, test_error(B): 0.17888851463794708, B-A: 0.04557766020298004\n",
            "epoch: 200, train_error(A): 0.1086459532380104, test_error(B): 0.21913492679595947, B-A: 0.11048897355794907\n",
            "epoch: 300, train_error(A): 0.07912198454141617, test_error(B): 0.13985566794872284, B-A: 0.06073368340730667\n",
            "epoch: 400, train_error(A): 0.09931717813014984, test_error(B): 0.22564439475536346, B-A: 0.12632721662521362\n",
            "epoch: 500, train_error(A): 0.051383331418037415, test_error(B): 0.13106012344360352, B-A: 0.0796767920255661\n",
            "epoch: 600, train_error(A): 0.06753654778003693, test_error(B): 0.18684178590774536, B-A: 0.11930523812770844\n",
            "epoch: 700, train_error(A): 0.02462942712008953, test_error(B): 0.15027983486652374, B-A: 0.12565040588378906\n",
            "epoch: 800, train_error(A): 0.020662441849708557, test_error(B): 0.17379039525985718, B-A: 0.15312795341014862\n",
            "epoch: 900, train_error(A): 0.010687891393899918, test_error(B): 0.18981795012950897, B-A: 0.17913006246089935\n",
            "epoch: 1000, train_error(A): 0.032573625445365906, test_error(B): 0.1853514164686203, B-A: 0.1527777910232544\n",
            "epoch: 1100, train_error(A): 0.006544879637658596, test_error(B): 0.1897936910390854, B-A: 0.18324881792068481\n",
            "epoch: 1200, train_error(A): 0.004393919836729765, test_error(B): 0.19758254289627075, B-A: 0.1931886225938797\n",
            "epoch: 1300, train_error(A): 0.013833425007760525, test_error(B): 0.17073538899421692, B-A: 0.15690197050571442\n",
            "epoch: 1400, train_error(A): 0.0060450974851846695, test_error(B): 0.1834755837917328, B-A: 0.17743048071861267\n",
            "epoch: 1500, train_error(A): 0.0035955922212451696, test_error(B): 0.18823716044425964, B-A: 0.18464156985282898\n",
            "epoch: 1600, train_error(A): 0.0024997801519930363, test_error(B): 0.1881556361913681, B-A: 0.1856558620929718\n",
            "epoch: 1700, train_error(A): 0.001674787956289947, test_error(B): 0.18882067501544952, B-A: 0.1871458888053894\n",
            "epoch: 1800, train_error(A): 0.0012620340567082167, test_error(B): 0.1891050636768341, B-A: 0.18784302473068237\n",
            "epoch: 1900, train_error(A): 0.0008883481496013701, test_error(B): 0.1893652379512787, B-A: 0.18847689032554626\n",
            "epoch: 2000, train_error(A): 0.0006556295556947589, test_error(B): 0.189416766166687, B-A: 0.1887611299753189\n",
            "epoch: 2100, train_error(A): 0.0007172011537477374, test_error(B): 0.18935427069664001, B-A: 0.18863706290721893\n",
            "epoch: 2200, train_error(A): 0.0005573881790041924, test_error(B): 0.18939785659313202, B-A: 0.18884046375751495\n",
            "epoch: 2300, train_error(A): 0.00046820033458061516, test_error(B): 0.18921025097370148, B-A: 0.18874205648899078\n",
            "epoch: 2400, train_error(A): 0.0020198377314954996, test_error(B): 0.18012602627277374, B-A: 0.1781061887741089\n",
            "epoch: 2500, train_error(A): 0.0005963402218185365, test_error(B): 0.18159553408622742, B-A: 0.18099918961524963\n",
            "epoch: 2600, train_error(A): 0.0003392571525182575, test_error(B): 0.1819452941417694, B-A: 0.18160603940486908\n",
            "epoch: 2700, train_error(A): 0.0002152237866539508, test_error(B): 0.1820710003376007, B-A: 0.18185578286647797\n",
            "epoch: 2800, train_error(A): 0.00014294989523477852, test_error(B): 0.18210987746715546, B-A: 0.18196693062782288\n",
            "epoch: 2900, train_error(A): 9.65171420830302e-05, test_error(B): 0.18211621046066284, B-A: 0.1820196956396103\n",
            "epoch: 3000, train_error(A): 8.597634587204084e-05, test_error(B): 0.182114839553833, B-A: 0.1820288598537445\n",
            "epoch: 3100, train_error(A): 0.005269802641123533, test_error(B): 0.19916854798793793, B-A: 0.1938987523317337\n",
            "epoch: 3200, train_error(A): 0.0019445957150310278, test_error(B): 0.208374485373497, B-A: 0.2064298838376999\n",
            "epoch: 3300, train_error(A): 0.0010375246638432145, test_error(B): 0.20959319174289703, B-A: 0.208555668592453\n",
            "epoch: 3400, train_error(A): 0.0005926029989495873, test_error(B): 0.21027925610542297, B-A: 0.20968665182590485\n",
            "epoch: 3500, train_error(A): 0.00035345263313502073, test_error(B): 0.21069689095020294, B-A: 0.21034343540668488\n",
            "epoch: 3600, train_error(A): 0.0002153478708351031, test_error(B): 0.2109409123659134, B-A: 0.2107255607843399\n",
            "epoch: 3700, train_error(A): 0.00013188159209676087, test_error(B): 0.21108198165893555, B-A: 0.21095010638237\n",
            "epoch: 3800, train_error(A): 8.047266601352021e-05, test_error(B): 0.21116387844085693, B-A: 0.21108341217041016\n",
            "epoch: 3900, train_error(A): 0.0005774024757556617, test_error(B): 0.2093140184879303, B-A: 0.2087366133928299\n",
            "epoch: 4000, train_error(A): 8.378827624255791e-05, test_error(B): 0.20967847108840942, B-A: 0.20959468185901642\n",
            "epoch: 4100, train_error(A): 4.241994975018315e-05, test_error(B): 0.2096792757511139, B-A: 0.209636852145195\n",
            "epoch: 4200, train_error(A): 0.0011078291572630405, test_error(B): 0.20252569019794464, B-A: 0.20141786336898804\n",
            "epoch: 4300, train_error(A): 0.00010343196481699124, test_error(B): 0.20287005603313446, B-A: 0.20276662707328796\n",
            "epoch: 4400, train_error(A): 4.929670103592798e-05, test_error(B): 0.20283359289169312, B-A: 0.20278429985046387\n",
            "epoch: 4500, train_error(A): 0.0015556279104202986, test_error(B): 0.19684655964374542, B-A: 0.1952909380197525\n",
            "epoch: 4600, train_error(A): 6.332139309961349e-05, test_error(B): 0.19890809059143066, B-A: 0.198844775557518\n",
            "epoch: 4700, train_error(A): 2.687267078727018e-05, test_error(B): 0.1989510953426361, B-A: 0.1989242285490036\n",
            "epoch: 4800, train_error(A): 0.0008170929504558444, test_error(B): 0.19479568302631378, B-A: 0.19397859275341034\n",
            "epoch: 4900, train_error(A): 6.052138996892609e-05, test_error(B): 0.1948617547750473, B-A: 0.1948012262582779\n",
            "epoch: 5000, train_error(A): 2.359695645282045e-05, test_error(B): 0.19487902522087097, B-A: 0.19485542178153992\n",
            "epoch: 5100, train_error(A): 0.09212139993906021, test_error(B): 0.172755628824234, B-A: 0.0806342288851738\n",
            "epoch: 5200, train_error(A): 0.019643420353531837, test_error(B): 0.20337443053722382, B-A: 0.18373100459575653\n",
            "epoch: 5300, train_error(A): 0.02896900847554207, test_error(B): 0.20930619537830353, B-A: 0.18033719062805176\n",
            "epoch: 5400, train_error(A): 0.008598816581070423, test_error(B): 0.21542535722255707, B-A: 0.20682653784751892\n",
            "epoch: 5500, train_error(A): 0.005107121542096138, test_error(B): 0.21755313873291016, B-A: 0.21244601905345917\n",
            "epoch: 5600, train_error(A): 0.0032027389388531446, test_error(B): 0.21873468160629272, B-A: 0.21553194522857666\n",
            "epoch: 5700, train_error(A): 0.0020655090920627117, test_error(B): 0.22017480432987213, B-A: 0.21810929477214813\n",
            "epoch: 5800, train_error(A): 0.0013551977463066578, test_error(B): 0.22163043916225433, B-A: 0.22027523815631866\n",
            "epoch: 5900, train_error(A): 0.0008962665451690555, test_error(B): 0.22289714217185974, B-A: 0.2220008820295334\n",
            "epoch: 6000, train_error(A): 0.0005927014863118529, test_error(B): 0.2238900363445282, B-A: 0.2232973277568817\n",
            "epoch: 6100, train_error(A): 0.00038898983621038496, test_error(B): 0.22461913526058197, B-A: 0.22423014044761658\n",
            "epoch: 6200, train_error(A): 0.0002517126267775893, test_error(B): 0.22513356804847717, B-A: 0.2248818576335907\n",
            "epoch: 6300, train_error(A): 0.0001598563976585865, test_error(B): 0.2254844605922699, B-A: 0.2253246009349823\n",
            "epoch: 6400, train_error(A): 9.93249996099621e-05, test_error(B): 0.22571679949760437, B-A: 0.22561746835708618\n",
            "epoch: 6500, train_error(A): 6.024813046678901e-05, test_error(B): 0.22586655616760254, B-A: 0.2258063107728958\n",
            "epoch: 6600, train_error(A): 3.561380799510516e-05, test_error(B): 0.22596043348312378, B-A: 0.22592481970787048\n",
            "epoch: 6700, train_error(A): 2.0484920241869986e-05, test_error(B): 0.22601760923862457, B-A: 0.22599712014198303\n",
            "epoch: 6800, train_error(A): 1.145382339018397e-05, test_error(B): 0.22605140507221222, B-A: 0.22603994607925415\n",
            "epoch: 6900, train_error(A): 6.212302196217934e-06, test_error(B): 0.22607071697711945, B-A: 0.2260645031929016\n",
            "epoch: 7000, train_error(A): 3.2630557598167798e-06, test_error(B): 0.22608156502246857, B-A: 0.22607830166816711\n",
            "epoch: 7100, train_error(A): 1.6618715790173155e-06, test_error(B): 0.22608736157417297, B-A: 0.22608569264411926\n",
            "epoch: 7200, train_error(A): 8.283824399768491e-07, test_error(B): 0.22609032690525055, B-A: 0.2260894924402237\n",
            "epoch: 7300, train_error(A): 4.2151864931838645e-07, test_error(B): 0.22609172761440277, B-A: 0.22609131038188934\n",
            "epoch: 7400, train_error(A): 2.2774470664899127e-07, test_error(B): 0.2260924130678177, B-A: 0.22609218955039978\n",
            "epoch: 7500, train_error(A): 1.4425381777982693e-07, test_error(B): 0.22609274089336395, B-A: 0.22609259188175201\n",
            "epoch: 7600, train_error(A): 1.003584060299545e-07, test_error(B): 0.22609291970729828, B-A: 0.22609281539916992\n",
            "epoch: 7700, train_error(A): 9.123375122044308e-08, test_error(B): 0.22609300911426544, B-A: 0.22609291970729828\n",
            "epoch: 7800, train_error(A): 0.003065194934606552, test_error(B): 0.22215481102466583, B-A: 0.21908961236476898\n",
            "epoch: 7900, train_error(A): 0.00013318612764123827, test_error(B): 0.22276566922664642, B-A: 0.2226324826478958\n",
            "epoch: 8000, train_error(A): 4.180955147603527e-05, test_error(B): 0.22296620905399323, B-A: 0.2229243963956833\n",
            "epoch: 8100, train_error(A): 1.3628095075546298e-05, test_error(B): 0.22303801774978638, B-A: 0.223024383187294\n",
            "epoch: 8200, train_error(A): 4.6496361392200924e-06, test_error(B): 0.22306200861930847, B-A: 0.223057359457016\n",
            "epoch: 8300, train_error(A): 0.0006769187748432159, test_error(B): 0.22057606279850006, B-A: 0.21989914774894714\n",
            "epoch: 8400, train_error(A): 3.7665267882402986e-05, test_error(B): 0.22075074911117554, B-A: 0.2207130789756775\n",
            "epoch: 8500, train_error(A): 1.0320241017325316e-05, test_error(B): 0.2208283543586731, B-A: 0.22081802785396576\n",
            "epoch: 8600, train_error(A): 2.765015324257547e-06, test_error(B): 0.22084946930408478, B-A: 0.22084669768810272\n",
            "epoch: 8700, train_error(A): 0.0074059562757611275, test_error(B): 0.22192279994487762, B-A: 0.21451684832572937\n",
            "epoch: 8800, train_error(A): 6.812264473410323e-05, test_error(B): 0.2191997766494751, B-A: 0.21913164854049683\n",
            "epoch: 8900, train_error(A): 2.034829776675906e-05, test_error(B): 0.21933870017528534, B-A: 0.21931834518909454\n",
            "epoch: 9000, train_error(A): 8.828460704535246e-05, test_error(B): 0.21884076297283173, B-A: 0.21875247359275818\n",
            "epoch: 9100, train_error(A): 9.198653970088344e-06, test_error(B): 0.21890071034431458, B-A: 0.21889151632785797\n",
            "epoch: 9200, train_error(A): 0.0005787830450572073, test_error(B): 0.21869418025016785, B-A: 0.2181154042482376\n",
            "epoch: 9300, train_error(A): 2.163901626772713e-05, test_error(B): 0.21898309886455536, B-A: 0.2189614623785019\n",
            "epoch: 9400, train_error(A): 0.0005029833992011845, test_error(B): 0.2177739143371582, B-A: 0.21727092564105988\n",
            "epoch: 9500, train_error(A): 1.3396744179772213e-05, test_error(B): 0.21824102103710175, B-A: 0.21822762489318848\n",
            "epoch: 9600, train_error(A): 0.0005028190207667649, test_error(B): 0.2184966653585434, B-A: 0.2179938405752182\n",
            "epoch: 9700, train_error(A): 0.030017925426363945, test_error(B): 0.1750268042087555, B-A: 0.1450088769197464\n",
            "epoch: 9800, train_error(A): 0.0023440979421138763, test_error(B): 0.1903131604194641, B-A: 0.18796905875205994\n",
            "epoch: 9900, train_error(A): 0.0009396779350936413, test_error(B): 0.19068153202533722, B-A: 0.189741849899292\n",
            "epoch: 10000, train_error(A): 0.0004425352963153273, test_error(B): 0.19069111347198486, B-A: 0.19024857878684998\n",
            "epoch: 10100, train_error(A): 0.00022327549231704324, test_error(B): 0.1906762272119522, B-A: 0.1904529482126236\n",
            "epoch: 10200, train_error(A): 0.00011483411071822047, test_error(B): 0.19066810607910156, B-A: 0.19055327773094177\n",
            "epoch: 10300, train_error(A): 5.879676973563619e-05, test_error(B): 0.19066278636455536, B-A: 0.19060398638248444\n",
            "epoch: 10400, train_error(A): 2.9583183277281933e-05, test_error(B): 0.1906585842370987, B-A: 0.1906290054321289\n",
            "epoch: 10500, train_error(A): 1.4503480088023935e-05, test_error(B): 0.1906554400920868, B-A: 0.19064094126224518\n",
            "epoch: 10600, train_error(A): 6.894087619002676e-06, test_error(B): 0.1906532496213913, B-A: 0.19064635038375854\n",
            "epoch: 10700, train_error(A): 3.1916135867504636e-06, test_error(B): 0.1906518042087555, B-A: 0.19064861536026\n",
            "epoch: 10800, train_error(A): 0.00014201969315763563, test_error(B): 0.19054296612739563, B-A: 0.19040094316005707\n",
            "epoch: 10900, train_error(A): 0.0011590730864554644, test_error(B): 0.19061127305030823, B-A: 0.18945220112800598\n",
            "epoch: 11000, train_error(A): 0.001270524924620986, test_error(B): 0.1898382008075714, B-A: 0.18856768310070038\n",
            "epoch: 11100, train_error(A): 0.0017627928173169494, test_error(B): 0.19038628041744232, B-A: 0.18862348794937134\n",
            "epoch: 11200, train_error(A): 0.004834952764213085, test_error(B): 0.1886758655309677, B-A: 0.18384091556072235\n",
            "epoch: 11300, train_error(A): 0.0001289423234993592, test_error(B): 0.18955902755260468, B-A: 0.1894300878047943\n",
            "epoch: 11400, train_error(A): 0.00010448724060552195, test_error(B): 0.18937061727046967, B-A: 0.1892661303281784\n",
            "epoch: 11500, train_error(A): 0.0005785988760180771, test_error(B): 0.1891082525253296, B-A: 0.18852965533733368\n",
            "epoch: 11600, train_error(A): 3.0396675356314518e-05, test_error(B): 0.1891244351863861, B-A: 0.18909403681755066\n",
            "epoch: 11700, train_error(A): 0.007552325259894133, test_error(B): 0.18722222745418549, B-A: 0.17966990172863007\n",
            "epoch: 11800, train_error(A): 0.001178052625618875, test_error(B): 0.18853849172592163, B-A: 0.18736043572425842\n",
            "epoch: 11900, train_error(A): 4.811849066754803e-05, test_error(B): 0.18947766721248627, B-A: 0.18942955136299133\n",
            "epoch: 12000, train_error(A): 0.001054495805874467, test_error(B): 0.18993915617465973, B-A: 0.1888846606016159\n",
            "epoch: 12100, train_error(A): 0.0007919069612398744, test_error(B): 0.18997277319431305, B-A: 0.1891808658838272\n",
            "epoch: 12200, train_error(A): 2.2924394215806387e-05, test_error(B): 0.1903551071882248, B-A: 0.19033218920230865\n",
            "epoch: 12300, train_error(A): 0.0019709859043359756, test_error(B): 0.19114992022514343, B-A: 0.189178928732872\n",
            "epoch: 12400, train_error(A): 0.00035093017504550517, test_error(B): 0.1910403072834015, B-A: 0.19068937003612518\n",
            "epoch: 12500, train_error(A): 0.00047771030222065747, test_error(B): 0.19122575223445892, B-A: 0.19074803590774536\n",
            "epoch: 12600, train_error(A): 0.0008187677594833076, test_error(B): 0.19184081256389618, B-A: 0.19102203845977783\n",
            "epoch: 12700, train_error(A): 8.519861876266077e-05, test_error(B): 0.19184795022010803, B-A: 0.1917627453804016\n",
            "epoch: 12800, train_error(A): 0.0016589113511145115, test_error(B): 0.19123969972133636, B-A: 0.1895807832479477\n",
            "epoch: 12900, train_error(A): 0.0003410034696571529, test_error(B): 0.19246354699134827, B-A: 0.19212254881858826\n",
            "epoch: 13000, train_error(A): 0.0012733715120702982, test_error(B): 0.19306111335754395, B-A: 0.1917877346277237\n",
            "epoch: 13100, train_error(A): 0.0009774232748895884, test_error(B): 0.1932220309972763, B-A: 0.19224460422992706\n",
            "epoch: 13200, train_error(A): 0.00010839188325917348, test_error(B): 0.1930982917547226, B-A: 0.19298990070819855\n",
            "epoch: 13300, train_error(A): 0.0004359721206128597, test_error(B): 0.19399216771125793, B-A: 0.19355618953704834\n",
            "epoch: 13400, train_error(A): 0.0030959846917539835, test_error(B): 0.1934473216533661, B-A: 0.19035133719444275\n",
            "epoch: 13500, train_error(A): 2.0153662262600847e-05, test_error(B): 0.194010391831398, B-A: 0.19399024546146393\n",
            "epoch: 13600, train_error(A): 0.003446808783337474, test_error(B): 0.19553817808628082, B-A: 0.19209137558937073\n",
            "epoch: 13700, train_error(A): 1.4145237400953192e-05, test_error(B): 0.19501499831676483, B-A: 0.19500085711479187\n",
            "epoch: 13800, train_error(A): 0.004331751726567745, test_error(B): 0.1962805837392807, B-A: 0.19194883108139038\n",
            "epoch: 13900, train_error(A): 1.364854415442096e-05, test_error(B): 0.19543606042861938, B-A: 0.19542241096496582\n",
            "epoch: 14000, train_error(A): 3.86150560416354e-07, test_error(B): 0.19543182849884033, B-A: 0.1954314410686493\n",
            "epoch: 14100, train_error(A): 0.0012730112066492438, test_error(B): 0.19888538122177124, B-A: 0.19761237502098083\n",
            "epoch: 14200, train_error(A): 0.003491533687338233, test_error(B): 0.1993449181318283, B-A: 0.19585338234901428\n",
            "epoch: 14300, train_error(A): 0.00013815904094371945, test_error(B): 0.19849081337451935, B-A: 0.19835264980793\n",
            "epoch: 14400, train_error(A): 0.00011808454291895032, test_error(B): 0.19858744740486145, B-A: 0.1984693557024002\n",
            "epoch: 14500, train_error(A): 0.0025099574122577906, test_error(B): 0.19953058660030365, B-A: 0.19702063500881195\n",
            "epoch: 14600, train_error(A): 4.327417627791874e-05, test_error(B): 0.1986212134361267, B-A: 0.19857794046401978\n",
            "epoch: 14700, train_error(A): 0.0004872163408435881, test_error(B): 0.19781367480754852, B-A: 0.1973264515399933\n",
            "epoch: 14800, train_error(A): 2.772451580312918e-06, test_error(B): 0.19799232482910156, B-A: 0.1979895532131195\n",
            "epoch: 14900, train_error(A): 0.003366978606209159, test_error(B): 0.19917364418506622, B-A: 0.19580666720867157\n",
            "epoch: 15000, train_error(A): 1.4727879715792369e-05, test_error(B): 0.19776830077171326, B-A: 0.19775357842445374\n",
            "epoch: 15100, train_error(A): 8.241245086537674e-05, test_error(B): 0.19774354994297028, B-A: 0.1976611316204071\n",
            "epoch: 15200, train_error(A): 0.00015148476813919842, test_error(B): 0.19745227694511414, B-A: 0.19730079174041748\n",
            "epoch: 15300, train_error(A): 0.00012484339822549373, test_error(B): 0.197446808218956, B-A: 0.19732196629047394\n",
            "epoch: 15400, train_error(A): 1.2653857993427664e-05, test_error(B): 0.1973886936903, B-A: 0.1973760426044464\n",
            "epoch: 15500, train_error(A): 0.00034797811531461775, test_error(B): 0.19715453684329987, B-A: 0.19680656492710114\n",
            "epoch: 15600, train_error(A): 1.6680490944054327e-06, test_error(B): 0.197299987077713, B-A: 0.1972983181476593\n",
            "epoch: 15700, train_error(A): 0.00011087239545304328, test_error(B): 0.19726616144180298, B-A: 0.19715528190135956\n",
            "epoch: 15800, train_error(A): 0.00012528884690254927, test_error(B): 0.19741080701351166, B-A: 0.1972855180501938\n",
            "epoch: 15900, train_error(A): 0.0006523561314679682, test_error(B): 0.19712767004966736, B-A: 0.1964753121137619\n",
            "epoch: 16000, train_error(A): 1.0954312529065646e-05, test_error(B): 0.19697286188602448, B-A: 0.196961909532547\n",
            "epoch: 16100, train_error(A): 0.006584065966308117, test_error(B): 0.19440078735351562, B-A: 0.18781672418117523\n",
            "epoch: 16200, train_error(A): 6.064086119295098e-05, test_error(B): 0.19557689130306244, B-A: 0.19551624357700348\n",
            "epoch: 16300, train_error(A): 6.62597187783831e-07, test_error(B): 0.19556114077568054, B-A: 0.195560485124588\n",
            "epoch: 16400, train_error(A): 0.005152506288141012, test_error(B): 0.1949343979358673, B-A: 0.18978188931941986\n",
            "epoch: 16500, train_error(A): 1.3737946574110538e-05, test_error(B): 0.19646964967250824, B-A: 0.1964559108018875\n",
            "epoch: 16600, train_error(A): 2.3668263793297228e-07, test_error(B): 0.19647541642189026, B-A: 0.19647517800331116\n",
            "epoch: 16700, train_error(A): 0.002626027911901474, test_error(B): 0.19572044909000397, B-A: 0.1930944174528122\n",
            "epoch: 16800, train_error(A): 6.367530295392498e-05, test_error(B): 0.19632133841514587, B-A: 0.19625766575336456\n",
            "epoch: 16900, train_error(A): 0.00010804458725033328, test_error(B): 0.19616453349590302, B-A: 0.19605648517608643\n",
            "epoch: 17000, train_error(A): 6.494804983958602e-05, test_error(B): 0.1961471140384674, B-A: 0.19608215987682343\n",
            "epoch: 17100, train_error(A): 0.00622806791216135, test_error(B): 0.17859245836734772, B-A: 0.17236438393592834\n",
            "epoch: 17200, train_error(A): 0.0009460689034312963, test_error(B): 0.17708826065063477, B-A: 0.17614218592643738\n",
            "epoch: 17300, train_error(A): 0.00025736901443451643, test_error(B): 0.17692919075489044, B-A: 0.1766718178987503\n",
            "epoch: 17400, train_error(A): 7.937332702567801e-05, test_error(B): 0.1769099086523056, B-A: 0.17683053016662598\n",
            "epoch: 17500, train_error(A): 2.8336035029496998e-05, test_error(B): 0.17690420150756836, B-A: 0.17687585949897766\n",
            "epoch: 17600, train_error(A): 1.1263206943112891e-05, test_error(B): 0.17690196633338928, B-A: 0.17689070105552673\n",
            "epoch: 17700, train_error(A): 4.606972197507275e-06, test_error(B): 0.17690105736255646, B-A: 0.17689645290374756\n",
            "epoch: 17800, train_error(A): 1.847117687248101e-06, test_error(B): 0.176900714635849, B-A: 0.17689886689186096\n",
            "epoch: 17900, train_error(A): 7.193505666691635e-07, test_error(B): 0.17690056562423706, B-A: 0.17689985036849976\n",
            "epoch: 18000, train_error(A): 2.912179581926466e-07, test_error(B): 0.1769004762172699, B-A: 0.17690017819404602\n",
            "epoch: 18100, train_error(A): 1.3613443172744155e-07, test_error(B): 0.1769004762172699, B-A: 0.17690034210681915\n",
            "epoch: 18200, train_error(A): 7.832947801489354e-08, test_error(B): 0.17690043151378632, B-A: 0.17690035700798035\n",
            "epoch: 18300, train_error(A): 1.238455809016159e-07, test_error(B): 0.1769004613161087, B-A: 0.17690034210681915\n",
            "epoch: 18400, train_error(A): 0.001402967725880444, test_error(B): 0.17702901363372803, B-A: 0.17562603950500488\n",
            "epoch: 18500, train_error(A): 2.559854692663066e-05, test_error(B): 0.1766481101512909, B-A: 0.17662250995635986\n",
            "epoch: 18600, train_error(A): 2.291152441102895e-06, test_error(B): 0.17665305733680725, B-A: 0.1766507625579834\n",
            "epoch: 18700, train_error(A): 0.004768224898725748, test_error(B): 0.17615200579166412, B-A: 0.1713837832212448\n",
            "epoch: 18800, train_error(A): 1.6337738998117857e-05, test_error(B): 0.1764066517353058, B-A: 0.17639032006263733\n",
            "epoch: 18900, train_error(A): 1.2413963759172475e-06, test_error(B): 0.17640404403209686, B-A: 0.17640280723571777\n",
            "epoch: 19000, train_error(A): 0.0005316032911650836, test_error(B): 0.17635653913021088, B-A: 0.17582494020462036\n",
            "epoch: 19100, train_error(A): 7.989132427610457e-05, test_error(B): 0.1762027144432068, B-A: 0.17612282931804657\n",
            "epoch: 19200, train_error(A): 1.3306380424182862e-06, test_error(B): 0.17620502412319183, B-A: 0.17620369791984558\n",
            "epoch: 19300, train_error(A): 3.66378770877418e-07, test_error(B): 0.1762043535709381, B-A: 0.17620398104190826\n",
            "epoch: 19400, train_error(A): 0.0007919971831142902, test_error(B): 0.17605672776699066, B-A: 0.17526473104953766\n",
            "epoch: 19500, train_error(A): 6.854429557279218e-06, test_error(B): 0.17608767747879028, B-A: 0.1760808229446411\n",
            "epoch: 19600, train_error(A): 5.063064918431337e-07, test_error(B): 0.1760857105255127, B-A: 0.1760852038860321\n",
            "epoch: 19700, train_error(A): 0.001363221905194223, test_error(B): 0.1763126254081726, B-A: 0.17494940757751465\n",
            "epoch: 19800, train_error(A): 2.0478850274230354e-05, test_error(B): 0.1759873777627945, B-A: 0.17596690356731415\n",
            "epoch: 19900, train_error(A): 6.390617954821209e-07, test_error(B): 0.17598983645439148, B-A: 0.17598919570446014\n",
            "epoch: 20000, train_error(A): 0.0019847333896905184, test_error(B): 0.1754433512687683, B-A: 0.17345862090587616\n",
            "epoch: 20100, train_error(A): 0.0013123039389029145, test_error(B): 0.17522785067558289, B-A: 0.1739155501127243\n",
            "epoch: 20200, train_error(A): 1.1638008800218813e-05, test_error(B): 0.17564883828163147, B-A: 0.17563720047473907\n",
            "epoch: 20300, train_error(A): 0.00020751719421241432, test_error(B): 0.17569546401500702, B-A: 0.1754879504442215\n",
            "epoch: 20400, train_error(A): 4.179037205176428e-05, test_error(B): 0.17539271712303162, B-A: 0.17535091936588287\n",
            "epoch: 20500, train_error(A): 0.001493067480623722, test_error(B): 0.17526406049728394, B-A: 0.1737709939479828\n",
            "epoch: 20600, train_error(A): 1.9529941710061394e-05, test_error(B): 0.1753968596458435, B-A: 0.17537732422351837\n",
            "epoch: 20700, train_error(A): 0.0009328672313131392, test_error(B): 0.17508184909820557, B-A: 0.17414897680282593\n",
            "epoch: 20800, train_error(A): 7.1782815211918205e-06, test_error(B): 0.17506040632724762, B-A: 0.17505322396755219\n",
            "epoch: 20900, train_error(A): 0.00022002535115461797, test_error(B): 0.17503291368484497, B-A: 0.17481288313865662\n",
            "epoch: 21000, train_error(A): 0.00043942060437984765, test_error(B): 0.17460617423057556, B-A: 0.1741667538881302\n",
            "epoch: 21100, train_error(A): 2.3595266611664556e-06, test_error(B): 0.17456817626953125, B-A: 0.17456582188606262\n",
            "epoch: 21200, train_error(A): 0.002076382515951991, test_error(B): 0.17468060553073883, B-A: 0.17260421812534332\n",
            "epoch: 21300, train_error(A): 1.5652525689802133e-05, test_error(B): 0.17436519265174866, B-A: 0.17434954643249512\n",
            "epoch: 21400, train_error(A): 0.0011706704972311854, test_error(B): 0.1738935261964798, B-A: 0.17272286117076874\n",
            "epoch: 21500, train_error(A): 0.000378976808860898, test_error(B): 0.17366740107536316, B-A: 0.17328841984272003\n",
            "epoch: 21600, train_error(A): 2.316650716238655e-05, test_error(B): 0.173674538731575, B-A: 0.17365136742591858\n",
            "epoch: 21700, train_error(A): 0.00018910403014160693, test_error(B): 0.1733866184949875, B-A: 0.17319750785827637\n",
            "epoch: 21800, train_error(A): 0.003816992277279496, test_error(B): 0.17357243597507477, B-A: 0.16975544393062592\n",
            "epoch: 21900, train_error(A): 1.5596217053825967e-05, test_error(B): 0.17338159680366516, B-A: 0.1733659952878952\n",
            "epoch: 22000, train_error(A): 0.0030369721353054047, test_error(B): 0.17192931473255157, B-A: 0.16889233887195587\n",
            "epoch: 22100, train_error(A): 1.2246851838426664e-05, test_error(B): 0.17274628579616547, B-A: 0.17273403704166412\n",
            "epoch: 22200, train_error(A): 0.0024467299226671457, test_error(B): 0.17199237644672394, B-A: 0.16954565048217773\n",
            "epoch: 22300, train_error(A): 1.5486975826206617e-05, test_error(B): 0.17246165871620178, B-A: 0.17244617640972137\n",
            "epoch: 22400, train_error(A): 0.0001307124039158225, test_error(B): 0.17263594269752502, B-A: 0.1725052297115326\n",
            "epoch: 22500, train_error(A): 0.001677798223681748, test_error(B): 0.17245075106620789, B-A: 0.1707729548215866\n",
            "epoch: 22600, train_error(A): 0.0038829422555863857, test_error(B): 0.17225860059261322, B-A: 0.1683756560087204\n",
            "epoch: 22700, train_error(A): 0.0035678748972713947, test_error(B): 0.1737595796585083, B-A: 0.1701917052268982\n",
            "epoch: 22800, train_error(A): 4.355917917564511e-05, test_error(B): 0.17259490489959717, B-A: 0.17255134880542755\n",
            "epoch: 22900, train_error(A): 0.0006449487409554422, test_error(B): 0.17266900837421417, B-A: 0.17202405631542206\n",
            "epoch: 23000, train_error(A): 0.0009666435071267188, test_error(B): 0.17241838574409485, B-A: 0.17145174741744995\n",
            "epoch: 23100, train_error(A): 0.0005002847174182534, test_error(B): 0.17233875393867493, B-A: 0.17183846235275269\n",
            "epoch: 23200, train_error(A): 0.0034858963917940855, test_error(B): 0.17419393360614777, B-A: 0.17070803046226501\n",
            "epoch: 23300, train_error(A): 0.00035942482645623386, test_error(B): 0.17252331972122192, B-A: 0.17216388881206512\n",
            "epoch: 23400, train_error(A): 0.0018710345029830933, test_error(B): 0.1724165678024292, B-A: 0.1705455332994461\n",
            "epoch: 23500, train_error(A): 0.0019180942326784134, test_error(B): 0.17135663330554962, B-A: 0.16943854093551636\n",
            "epoch: 23600, train_error(A): 0.0014435634948313236, test_error(B): 0.17271870374679565, B-A: 0.17127513885498047\n",
            "epoch: 23700, train_error(A): 0.000845811446197331, test_error(B): 0.17213165760040283, B-A: 0.17128585278987885\n",
            "epoch: 23800, train_error(A): 0.0008861147216521204, test_error(B): 0.17229536175727844, B-A: 0.1714092493057251\n",
            "epoch: 23900, train_error(A): 0.0011051343753933907, test_error(B): 0.17140139639377594, B-A: 0.17029626667499542\n",
            "epoch: 24000, train_error(A): 0.0008898301748558879, test_error(B): 0.1718672811985016, B-A: 0.17097745835781097\n",
            "epoch: 24100, train_error(A): 0.0025910534895956516, test_error(B): 0.1729932576417923, B-A: 0.17040219902992249\n",
            "epoch: 24200, train_error(A): 0.0004134307091590017, test_error(B): 0.17187714576721191, B-A: 0.1714637130498886\n",
            "epoch: 24300, train_error(A): 0.0015923345927149057, test_error(B): 0.17109209299087524, B-A: 0.16949975490570068\n",
            "epoch: 24400, train_error(A): 0.0017473017796874046, test_error(B): 0.17196893692016602, B-A: 0.17022164165973663\n",
            "epoch: 24500, train_error(A): 0.0008553550578653812, test_error(B): 0.1713196337223053, B-A: 0.17046427726745605\n",
            "epoch: 24600, train_error(A): 0.0007599731325171888, test_error(B): 0.1713879555463791, B-A: 0.17062798142433167\n",
            "epoch: 24700, train_error(A): 0.00010822334297699854, test_error(B): 0.17155446112155914, B-A: 0.17144623398780823\n",
            "epoch: 24800, train_error(A): 0.00030409530154429376, test_error(B): 0.17166993021965027, B-A: 0.17136584222316742\n",
            "epoch: 24900, train_error(A): 0.0018848029430955648, test_error(B): 0.17239388823509216, B-A: 0.17050908505916595\n",
            "epoch: 25000, train_error(A): 0.001207717228680849, test_error(B): 0.17181243002414703, B-A: 0.17060470581054688\n",
            "epoch: 25100, train_error(A): 0.0008164548198692501, test_error(B): 0.17166461050510406, B-A: 0.17084816098213196\n",
            "epoch: 25200, train_error(A): 0.0006948680966161191, test_error(B): 0.1718030869960785, B-A: 0.171108216047287\n",
            "epoch: 25300, train_error(A): 0.00442878995090723, test_error(B): 0.17264936864376068, B-A: 0.16822057962417603\n",
            "epoch: 25400, train_error(A): 3.082264447584748e-05, test_error(B): 0.1715088188648224, B-A: 0.1714780032634735\n",
            "epoch: 25500, train_error(A): 0.00021547598589677364, test_error(B): 0.17215147614479065, B-A: 0.1719360053539276\n",
            "epoch: 25600, train_error(A): 0.00011213677498744801, test_error(B): 0.1719636619091034, B-A: 0.1718515306711197\n",
            "epoch: 25700, train_error(A): 0.000799032102804631, test_error(B): 0.17140141129493713, B-A: 0.17060238122940063\n",
            "epoch: 25800, train_error(A): 0.0003360352129675448, test_error(B): 0.17145667970180511, B-A: 0.17112064361572266\n",
            "epoch: 25900, train_error(A): 0.0013925611274316907, test_error(B): 0.1723981648683548, B-A: 0.17100560665130615\n",
            "epoch: 26000, train_error(A): 0.0013300551800057292, test_error(B): 0.17126083374023438, B-A: 0.16993078589439392\n",
            "epoch: 26100, train_error(A): 5.624643017654307e-05, test_error(B): 0.1714828461408615, B-A: 0.17142659425735474\n",
            "epoch: 26200, train_error(A): 0.00033108858042396605, test_error(B): 0.17137955129146576, B-A: 0.17104846239089966\n",
            "epoch: 26300, train_error(A): 0.00014795470633544028, test_error(B): 0.171132892370224, B-A: 0.17098493874073029\n",
            "epoch: 26400, train_error(A): 0.001224206993356347, test_error(B): 0.17130021750926971, B-A: 0.17007601261138916\n",
            "epoch: 26500, train_error(A): 0.0032784666400402784, test_error(B): 0.1727677583694458, B-A: 0.1694892942905426\n",
            "epoch: 26600, train_error(A): 0.000981642515398562, test_error(B): 0.17219918966293335, B-A: 0.17121754586696625\n",
            "epoch: 26700, train_error(A): 0.001947482000105083, test_error(B): 0.17224977910518646, B-A: 0.17030230164527893\n",
            "epoch: 26800, train_error(A): 0.0008714161813259125, test_error(B): 0.17186231911182404, B-A: 0.17099089920520782\n",
            "epoch: 26900, train_error(A): 0.002472633495926857, test_error(B): 0.1712779998779297, B-A: 0.16880536079406738\n",
            "epoch: 27000, train_error(A): 0.0013518402120098472, test_error(B): 0.17232120037078857, B-A: 0.17096936702728271\n",
            "epoch: 27100, train_error(A): 0.002143832389265299, test_error(B): 0.1723063588142395, B-A: 0.17016252875328064\n",
            "epoch: 27200, train_error(A): 0.00029135349905118346, test_error(B): 0.17155243456363678, B-A: 0.17126108705997467\n",
            "epoch: 27300, train_error(A): 0.00028543974622152746, test_error(B): 0.1713417023420334, B-A: 0.17105625569820404\n",
            "epoch: 27400, train_error(A): 0.0008351139258593321, test_error(B): 0.17158618569374084, B-A: 0.17075106501579285\n",
            "epoch: 27500, train_error(A): 0.0009806128218770027, test_error(B): 0.17248089611530304, B-A: 0.1715002804994583\n",
            "epoch: 27600, train_error(A): 0.0016327215125784278, test_error(B): 0.17243704199790955, B-A: 0.17080432176589966\n",
            "epoch: 27700, train_error(A): 0.00020140284323133528, test_error(B): 0.17251619696617126, B-A: 0.17231479287147522\n",
            "epoch: 27800, train_error(A): 0.0003539634926710278, test_error(B): 0.17212000489234924, B-A: 0.17176604270935059\n",
            "epoch: 27900, train_error(A): 0.0011366676772013307, test_error(B): 0.171913281083107, B-A: 0.1707766205072403\n",
            "epoch: 28000, train_error(A): 0.0006902007153257728, test_error(B): 0.17270253598690033, B-A: 0.1720123291015625\n",
            "epoch: 28100, train_error(A): 0.00038338283775374293, test_error(B): 0.17236623167991638, B-A: 0.17198285460472107\n",
            "epoch: 28200, train_error(A): 0.0012658810010179877, test_error(B): 0.17187058925628662, B-A: 0.17060470581054688\n",
            "epoch: 28300, train_error(A): 0.0003383879957254976, test_error(B): 0.1726873219013214, B-A: 0.17234893143177032\n",
            "epoch: 28400, train_error(A): 0.03385457769036293, test_error(B): 0.1883968561887741, B-A: 0.15454228222370148\n",
            "epoch: 28500, train_error(A): 0.0005317296599969268, test_error(B): 0.17851603031158447, B-A: 0.1779842972755432\n",
            "epoch: 28600, train_error(A): 6.979395402595401e-05, test_error(B): 0.17837919294834137, B-A: 0.1783093959093094\n",
            "epoch: 28700, train_error(A): 1.4776433090446517e-05, test_error(B): 0.17838451266288757, B-A: 0.17836973071098328\n",
            "epoch: 28800, train_error(A): 3.2055977499112487e-06, test_error(B): 0.17838844656944275, B-A: 0.17838524281978607\n",
            "epoch: 28900, train_error(A): 6.60815430819639e-07, test_error(B): 0.1783895641565323, B-A: 0.17838890850543976\n",
            "epoch: 29000, train_error(A): 1.533257432129176e-07, test_error(B): 0.1783897578716278, B-A: 0.17838960886001587\n",
            "epoch: 29100, train_error(A): 7.012181413301732e-08, test_error(B): 0.1783898025751114, B-A: 0.17838972806930542\n",
            "epoch: 29200, train_error(A): 4.720885726783308e-08, test_error(B): 0.17838983237743378, B-A: 0.1783897876739502\n",
            "epoch: 29300, train_error(A): 5.206097242194119e-08, test_error(B): 0.17838983237743378, B-A: 0.1783897876739502\n",
            "epoch: 29400, train_error(A): 5.856322005115544e-08, test_error(B): 0.17838984727859497, B-A: 0.1783897876739502\n",
            "epoch: 29500, train_error(A): 5.458604235286657e-08, test_error(B): 0.17838983237743378, B-A: 0.178389772772789\n",
            "epoch: 29600, train_error(A): 5.4280963723840614e-08, test_error(B): 0.1783897876739502, B-A: 0.17838972806930542\n",
            "epoch: 29700, train_error(A): 7.44459072166137e-08, test_error(B): 0.1783898025751114, B-A: 0.17838972806930542\n",
            "epoch: 29800, train_error(A): 9.06830308622375e-08, test_error(B): 0.17838981747627258, B-A: 0.17838972806930542\n",
            "epoch: 29900, train_error(A): 5.368884004042229e-08, test_error(B): 0.17838981747627258, B-A: 0.1783897578716278\n",
            "epoch: 30000, train_error(A): 7.607440721812964e-08, test_error(B): 0.17838983237743378, B-A: 0.1783897578716278\n",
            "epoch: 30100, train_error(A): 7.314641692346413e-08, test_error(B): 0.17838984727859497, B-A: 0.178389772772789\n",
            "epoch: 30200, train_error(A): 7.320714701108955e-08, test_error(B): 0.17838981747627258, B-A: 0.1783897429704666\n",
            "epoch: 30300, train_error(A): 1.747100952798064e-07, test_error(B): 0.17838987708091736, B-A: 0.17838969826698303\n",
            "epoch: 30400, train_error(A): 5.309989774104906e-06, test_error(B): 0.17838840186595917, B-A: 0.17838309705257416\n",
            "epoch: 30500, train_error(A): 6.126710650278255e-05, test_error(B): 0.17824667692184448, B-A: 0.17818540334701538\n",
            "epoch: 30600, train_error(A): 8.33123408483516e-07, test_error(B): 0.17823821306228638, B-A: 0.17823737859725952\n",
            "epoch: 30700, train_error(A): 6.164654564599914e-08, test_error(B): 0.17823798954486847, B-A: 0.1782379299402237\n",
            "epoch: 30800, train_error(A): 8.952267904760447e-08, test_error(B): 0.17823803424835205, B-A: 0.1782379448413849\n",
            "epoch: 30900, train_error(A): 2.0249019883067376e-07, test_error(B): 0.17823795974254608, B-A: 0.17823775112628937\n",
            "epoch: 31000, train_error(A): 0.0002598542196210474, test_error(B): 0.17798401415348053, B-A: 0.17772415280342102\n",
            "epoch: 31100, train_error(A): 1.7162764152089949e-06, test_error(B): 0.17794255912303925, B-A: 0.17794084548950195\n",
            "epoch: 31200, train_error(A): 1.183841931151619e-07, test_error(B): 0.17794232070446014, B-A: 0.1779422014951706\n",
            "epoch: 31300, train_error(A): 0.00042304443195462227, test_error(B): 0.17786557972431183, B-A: 0.1774425357580185\n",
            "epoch: 31400, train_error(A): 0.004418771713972092, test_error(B): 0.17590752243995667, B-A: 0.17148874700069427\n",
            "epoch: 31500, train_error(A): 2.9116574296494946e-05, test_error(B): 0.1772380918264389, B-A: 0.17720897495746613\n",
            "epoch: 31600, train_error(A): 0.0003620517672970891, test_error(B): 0.17657287418842316, B-A: 0.17621082067489624\n",
            "epoch: 31700, train_error(A): 0.00010753912647487596, test_error(B): 0.17664256691932678, B-A: 0.17653502523899078\n",
            "epoch: 31800, train_error(A): 6.603675137739629e-05, test_error(B): 0.17648956179618835, B-A: 0.17642351984977722\n",
            "epoch: 31900, train_error(A): 0.0003526134241838008, test_error(B): 0.17586803436279297, B-A: 0.17551542818546295\n",
            "epoch: 32000, train_error(A): 0.0002399300574325025, test_error(B): 0.1759311854839325, B-A: 0.17569126188755035\n",
            "epoch: 32100, train_error(A): 2.2197526050149463e-05, test_error(B): 0.17587023973464966, B-A: 0.17584803700447083\n",
            "epoch: 32200, train_error(A): 0.00015016920224297792, test_error(B): 0.17522579431533813, B-A: 0.17507562041282654\n",
            "epoch: 32300, train_error(A): 0.00019617483485490084, test_error(B): 0.17504867911338806, B-A: 0.17485250532627106\n",
            "epoch: 32400, train_error(A): 7.71076520322822e-05, test_error(B): 0.17509399354457855, B-A: 0.1750168800354004\n",
            "epoch: 32500, train_error(A): 9.947308717528358e-05, test_error(B): 0.1745494157075882, B-A: 0.17444993555545807\n",
            "epoch: 32600, train_error(A): 0.00022010327666066587, test_error(B): 0.17408902943134308, B-A: 0.17386892437934875\n",
            "epoch: 32700, train_error(A): 2.335075805603992e-06, test_error(B): 0.17420190572738647, B-A: 0.17419956624507904\n",
            "epoch: 32800, train_error(A): 0.00039967038901522756, test_error(B): 0.17381925880908966, B-A: 0.17341959476470947\n",
            "epoch: 32900, train_error(A): 0.0022917327005416155, test_error(B): 0.17432339489459991, B-A: 0.17203165590763092\n",
            "epoch: 33000, train_error(A): 1.5344019629992545e-05, test_error(B): 0.173418790102005, B-A: 0.17340344190597534\n",
            "epoch: 33100, train_error(A): 0.0003725986462086439, test_error(B): 0.17288632690906525, B-A: 0.17251372337341309\n",
            "epoch: 33200, train_error(A): 0.00010867989476537332, test_error(B): 0.17270208895206451, B-A: 0.17259341478347778\n",
            "epoch: 33300, train_error(A): 0.0005638514994643629, test_error(B): 0.1728406399488449, B-A: 0.1722767949104309\n",
            "epoch: 33400, train_error(A): 0.0010228921892121434, test_error(B): 0.17293263971805573, B-A: 0.17190974950790405\n",
            "epoch: 33500, train_error(A): 0.0008442862308584154, test_error(B): 0.17220036685466766, B-A: 0.17135608196258545\n",
            "epoch: 33600, train_error(A): 0.004561862908303738, test_error(B): 0.17356185615062714, B-A: 0.16899999976158142\n",
            "epoch: 33700, train_error(A): 0.0012086016358807683, test_error(B): 0.17164286971092224, B-A: 0.17043426632881165\n",
            "epoch: 33800, train_error(A): 0.0008066418231464922, test_error(B): 0.17074526846408844, B-A: 0.16993862390518188\n",
            "epoch: 33900, train_error(A): 0.0012089357478544116, test_error(B): 0.17056874930858612, B-A: 0.16935981810092926\n",
            "epoch: 34000, train_error(A): 0.0024530622176826, test_error(B): 0.16958360373973846, B-A: 0.16713054478168488\n",
            "epoch: 34100, train_error(A): 0.0016718601109459996, test_error(B): 0.17021597921848297, B-A: 0.16854411363601685\n",
            "epoch: 34200, train_error(A): 0.0019425366772338748, test_error(B): 0.1716967076063156, B-A: 0.16975417733192444\n",
            "epoch: 34300, train_error(A): 0.0007633650675415993, test_error(B): 0.17034606635570526, B-A: 0.16958269476890564\n",
            "epoch: 34400, train_error(A): 0.0017986517632380128, test_error(B): 0.17142640054225922, B-A: 0.16962775588035583\n",
            "epoch: 34500, train_error(A): 0.000502880138810724, test_error(B): 0.17044804990291595, B-A: 0.16994516551494598\n",
            "epoch: 34600, train_error(A): 0.00012430292554199696, test_error(B): 0.17065928876399994, B-A: 0.17053498327732086\n",
            "epoch: 34700, train_error(A): 0.0005347717669792473, test_error(B): 0.1701478511095047, B-A: 0.1696130782365799\n",
            "epoch: 34800, train_error(A): 0.0020703214686363935, test_error(B): 0.1691003441810608, B-A: 0.16703002154827118\n",
            "epoch: 34900, train_error(A): 0.0006976237636990845, test_error(B): 0.16982212662696838, B-A: 0.16912449896335602\n",
            "epoch: 35000, train_error(A): 0.0003401805297471583, test_error(B): 0.169602170586586, B-A: 0.16926199197769165\n",
            "epoch: 35100, train_error(A): 0.002573091769590974, test_error(B): 0.17090770602226257, B-A: 0.16833461821079254\n",
            "epoch: 35200, train_error(A): 0.00023236814013216645, test_error(B): 0.16917924582958221, B-A: 0.16894687712192535\n",
            "epoch: 35300, train_error(A): 6.257437053136528e-05, test_error(B): 0.1693444550037384, B-A: 0.16928188502788544\n",
            "epoch: 35400, train_error(A): 0.0023139026015996933, test_error(B): 0.16833928227424622, B-A: 0.16602538526058197\n",
            "epoch: 35500, train_error(A): 1.2847633115598e-05, test_error(B): 0.16919270157814026, B-A: 0.16917985677719116\n",
            "epoch: 35600, train_error(A): 0.0005977005930617452, test_error(B): 0.16838441789150238, B-A: 0.16778671741485596\n",
            "epoch: 35700, train_error(A): 0.0005666787037625909, test_error(B): 0.1684998869895935, B-A: 0.16793321073055267\n",
            "epoch: 35800, train_error(A): 0.0012550761457532644, test_error(B): 0.16923287510871887, B-A: 0.16797779500484467\n",
            "epoch: 35900, train_error(A): 0.0003594418813008815, test_error(B): 0.1684010922908783, B-A: 0.1680416464805603\n",
            "epoch: 36000, train_error(A): 0.002654255134984851, test_error(B): 0.16966530680656433, B-A: 0.1670110523700714\n",
            "epoch: 36100, train_error(A): 0.0016088339034467936, test_error(B): 0.16844090819358826, B-A: 0.1668320745229721\n",
            "epoch: 36200, train_error(A): 0.0013088781852275133, test_error(B): 0.16809605062007904, B-A: 0.16678717732429504\n",
            "epoch: 36300, train_error(A): 0.0002904030552599579, test_error(B): 0.16864065825939178, B-A: 0.1683502495288849\n",
            "epoch: 36400, train_error(A): 0.00039565874612890184, test_error(B): 0.16850978136062622, B-A: 0.16811412572860718\n",
            "epoch: 36500, train_error(A): 0.00016481227066833526, test_error(B): 0.16819708049297333, B-A: 0.16803227365016937\n",
            "epoch: 36600, train_error(A): 0.0011318891774863005, test_error(B): 0.16886572539806366, B-A: 0.167733833193779\n",
            "epoch: 36700, train_error(A): 0.0002807218115776777, test_error(B): 0.1683039367198944, B-A: 0.1680232137441635\n",
            "epoch: 36800, train_error(A): 0.0004769166698679328, test_error(B): 0.1680944710969925, B-A: 0.1676175594329834\n",
            "epoch: 36900, train_error(A): 0.00034456636058166623, test_error(B): 0.16798165440559387, B-A: 0.16763709485530853\n",
            "epoch: 37000, train_error(A): 0.00017245416529476643, test_error(B): 0.16792459785938263, B-A: 0.16775214672088623\n",
            "epoch: 37100, train_error(A): 0.0026213834062218666, test_error(B): 0.16807177662849426, B-A: 0.16545039415359497\n",
            "epoch: 37200, train_error(A): 0.0017815548926591873, test_error(B): 0.16867327690124512, B-A: 0.16689172387123108\n",
            "epoch: 37300, train_error(A): 0.00029792069108225405, test_error(B): 0.16776436567306519, B-A: 0.1674664467573166\n",
            "epoch: 37400, train_error(A): 0.001592284650541842, test_error(B): 0.16876010596752167, B-A: 0.16716782748699188\n",
            "epoch: 37500, train_error(A): 0.0018031395738944411, test_error(B): 0.16807399690151215, B-A: 0.16627085208892822\n",
            "epoch: 37600, train_error(A): 0.0009143647039309144, test_error(B): 0.1677888184785843, B-A: 0.1668744534254074\n",
            "epoch: 37700, train_error(A): 0.0002727766695898026, test_error(B): 0.1676713228225708, B-A: 0.16739854216575623\n",
            "epoch: 37800, train_error(A): 0.0011908317683264613, test_error(B): 0.16754406690597534, B-A: 0.166353240609169\n",
            "epoch: 37900, train_error(A): 0.0004237355024088174, test_error(B): 0.16774311661720276, B-A: 0.1673193871974945\n",
            "epoch: 38000, train_error(A): 0.0036652926355600357, test_error(B): 0.15870682895183563, B-A: 0.15504153072834015\n",
            "epoch: 38100, train_error(A): 1.8360580725129694e-05, test_error(B): 0.1585409939289093, B-A: 0.15852263569831848\n",
            "epoch: 38200, train_error(A): 1.0723356780317772e-07, test_error(B): 0.15854384005069733, B-A: 0.15854373574256897\n",
            "epoch: 38300, train_error(A): 8.533865525350848e-08, test_error(B): 0.15854382514953613, B-A: 0.15854373574256897\n",
            "epoch: 38400, train_error(A): 7.167989792833396e-07, test_error(B): 0.15854407846927643, B-A: 0.15854336321353912\n",
            "epoch: 38500, train_error(A): 3.535627547535114e-05, test_error(B): 0.15818433463573456, B-A: 0.15814897418022156\n",
            "epoch: 38600, train_error(A): 1.375563329020224e-06, test_error(B): 0.15817278623580933, B-A: 0.1581714153289795\n",
            "epoch: 38700, train_error(A): 1.3948476862424286e-07, test_error(B): 0.1581733375787735, B-A: 0.15817320346832275\n",
            "epoch: 38800, train_error(A): 0.0039494214579463005, test_error(B): 0.15662091970443726, B-A: 0.15267150104045868\n",
            "epoch: 38900, train_error(A): 1.467562742618611e-05, test_error(B): 0.15777967870235443, B-A: 0.1577650010585785\n",
            "epoch: 39000, train_error(A): 1.885099152332259e-07, test_error(B): 0.15777477622032166, B-A: 0.15777458250522614\n",
            "epoch: 39100, train_error(A): 1.0799428196150984e-07, test_error(B): 0.1577746570110321, B-A: 0.15777455270290375\n",
            "epoch: 39200, train_error(A): 0.0009706249693408608, test_error(B): 0.15732114017009735, B-A: 0.1563505083322525\n",
            "epoch: 39300, train_error(A): 7.13799090590328e-06, test_error(B): 0.15772639214992523, B-A: 0.15771925449371338\n",
            "epoch: 39400, train_error(A): 2.8758861958522175e-07, test_error(B): 0.157728910446167, B-A: 0.1577286273241043\n",
            "epoch: 39500, train_error(A): 0.000809107325039804, test_error(B): 0.1583317667245865, B-A: 0.15752266347408295\n",
            "epoch: 39600, train_error(A): 0.0001361884642392397, test_error(B): 0.15822555124759674, B-A: 0.15808936953544617\n",
            "epoch: 39700, train_error(A): 5.423351922217989e-06, test_error(B): 0.15826772153377533, B-A: 0.15826229751110077\n",
            "epoch: 39800, train_error(A): 0.00014179831487126648, test_error(B): 0.15878398716449738, B-A: 0.15864218771457672\n",
            "epoch: 39900, train_error(A): 0.00029351990087889135, test_error(B): 0.1590205579996109, B-A: 0.1587270349264145\n",
            "epoch: 40000, train_error(A): 0.00010933852900052443, test_error(B): 0.15890663862228394, B-A: 0.15879729390144348\n",
            "epoch: 40100, train_error(A): 0.0007537961937487125, test_error(B): 0.15939630568027496, B-A: 0.15864251554012299\n",
            "epoch: 40200, train_error(A): 4.093695679330267e-05, test_error(B): 0.15909090638160706, B-A: 0.15904997289180756\n",
            "epoch: 40300, train_error(A): 0.000738082337193191, test_error(B): 0.15948732197284698, B-A: 0.15874923765659332\n",
            "epoch: 40400, train_error(A): 0.001643198193050921, test_error(B): 0.16049712896347046, B-A: 0.1588539332151413\n",
            "epoch: 40500, train_error(A): 0.0004188355233054608, test_error(B): 0.15986107289791107, B-A: 0.1594422310590744\n",
            "epoch: 40600, train_error(A): 0.0011623387690633535, test_error(B): 0.15952058136463165, B-A: 0.15835824608802795\n",
            "epoch: 40700, train_error(A): 0.00020600433344952762, test_error(B): 0.15975038707256317, B-A: 0.15954437851905823\n",
            "epoch: 40800, train_error(A): 0.0005840854137204587, test_error(B): 0.15981629490852356, B-A: 0.1592322140932083\n",
            "epoch: 40900, train_error(A): 0.0009874692186713219, test_error(B): 0.15967999398708344, B-A: 0.15869252383708954\n",
            "epoch: 41000, train_error(A): 6.317363295238465e-05, test_error(B): 0.16038314998149872, B-A: 0.1603199690580368\n",
            "epoch: 41100, train_error(A): 0.0005708548123948276, test_error(B): 0.160261869430542, B-A: 0.15969102084636688\n",
            "epoch: 41200, train_error(A): 0.0002479405957274139, test_error(B): 0.1606447994709015, B-A: 0.16039685904979706\n",
            "epoch: 41300, train_error(A): 0.0009967581136152148, test_error(B): 0.1610194593667984, B-A: 0.16002270579338074\n",
            "epoch: 41400, train_error(A): 0.00025208303122781217, test_error(B): 0.1608637124300003, B-A: 0.16061162948608398\n",
            "epoch: 41500, train_error(A): 9.13954499992542e-05, test_error(B): 0.16137167811393738, B-A: 0.1612802892923355\n",
            "epoch: 41600, train_error(A): 0.00045282571227289736, test_error(B): 0.16142109036445618, B-A: 0.16096825897693634\n",
            "epoch: 41700, train_error(A): 4.306038681534119e-05, test_error(B): 0.16158320009708405, B-A: 0.16154013574123383\n",
            "epoch: 41800, train_error(A): 0.000596388999838382, test_error(B): 0.16134612262248993, B-A: 0.16074973344802856\n",
            "epoch: 41900, train_error(A): 0.0015507873613387346, test_error(B): 0.16275085508823395, B-A: 0.16120006144046783\n",
            "epoch: 42000, train_error(A): 0.0007622340926900506, test_error(B): 0.1621415615081787, B-A: 0.16137932240962982\n",
            "epoch: 42100, train_error(A): 0.00014251920219976455, test_error(B): 0.16277649998664856, B-A: 0.1626339852809906\n",
            "epoch: 42200, train_error(A): 0.00013499814667738974, test_error(B): 0.16226840019226074, B-A: 0.16213339567184448\n",
            "epoch: 42300, train_error(A): 5.395918924477883e-05, test_error(B): 0.16270723938941956, B-A: 0.16265328228473663\n",
            "epoch: 42400, train_error(A): 0.001742027117870748, test_error(B): 0.164082333445549, B-A: 0.16234031319618225\n",
            "epoch: 42500, train_error(A): 0.0008895039791241288, test_error(B): 0.16291292011737823, B-A: 0.1620234102010727\n",
            "epoch: 42600, train_error(A): 0.0005117334076203406, test_error(B): 0.1631881445646286, B-A: 0.16267640888690948\n",
            "epoch: 42700, train_error(A): 0.0006801341660320759, test_error(B): 0.16322113573551178, B-A: 0.162541002035141\n",
            "epoch: 42800, train_error(A): 0.0006909624789841473, test_error(B): 0.16347651183605194, B-A: 0.16278554499149323\n",
            "epoch: 42900, train_error(A): 0.0005155102699063718, test_error(B): 0.1633625328540802, B-A: 0.16284702718257904\n",
            "epoch: 43000, train_error(A): 0.0003612824948504567, test_error(B): 0.16396625339984894, B-A: 0.1636049747467041\n",
            "epoch: 43100, train_error(A): 0.0011094989022240043, test_error(B): 0.16485172510147095, B-A: 0.16374222934246063\n",
            "epoch: 43200, train_error(A): 0.002441252116113901, test_error(B): 0.16338489949703217, B-A: 0.1609436422586441\n",
            "epoch: 43300, train_error(A): 0.0013045750092715025, test_error(B): 0.1637847125530243, B-A: 0.16248013079166412\n",
            "epoch: 43400, train_error(A): 0.0002633749390952289, test_error(B): 0.164358451962471, B-A: 0.16409507393836975\n",
            "epoch: 43500, train_error(A): 0.0005274447612464428, test_error(B): 0.16458328068256378, B-A: 0.16405583918094635\n",
            "epoch: 43600, train_error(A): 0.001480322447605431, test_error(B): 0.1649397313594818, B-A: 0.1634594053030014\n",
            "epoch: 43700, train_error(A): 0.0002217996516264975, test_error(B): 0.16390305757522583, B-A: 0.1636812537908554\n",
            "epoch: 43800, train_error(A): 0.000739628856536001, test_error(B): 0.16416369378566742, B-A: 0.1634240597486496\n",
            "epoch: 43900, train_error(A): 0.00019143322424497455, test_error(B): 0.16497603058815002, B-A: 0.16478459537029266\n",
            "epoch: 44000, train_error(A): 0.002303279936313629, test_error(B): 0.16733339428901672, B-A: 0.1650301218032837\n",
            "epoch: 44100, train_error(A): 0.00029635653481818736, test_error(B): 0.16531004011631012, B-A: 0.16501368582248688\n",
            "epoch: 44200, train_error(A): 0.0009513892000541091, test_error(B): 0.1651851385831833, B-A: 0.1642337441444397\n",
            "epoch: 44300, train_error(A): 0.0015365255530923605, test_error(B): 0.16462452709674835, B-A: 0.16308800876140594\n",
            "epoch: 44400, train_error(A): 0.0008752453722991049, test_error(B): 0.16505201160907745, B-A: 0.16417676210403442\n",
            "epoch: 44500, train_error(A): 0.0009575624717399478, test_error(B): 0.16533192992210388, B-A: 0.16437436640262604\n",
            "epoch: 44600, train_error(A): 0.000596735451836139, test_error(B): 0.16570445895195007, B-A: 0.16510772705078125\n",
            "epoch: 44700, train_error(A): 0.0011303836945444345, test_error(B): 0.16603915393352509, B-A: 0.164908766746521\n",
            "epoch: 44800, train_error(A): 0.0002688208769541234, test_error(B): 0.1661132276058197, B-A: 0.1658444106578827\n",
            "epoch: 44900, train_error(A): 9.464699542149901e-05, test_error(B): 0.16583439707756042, B-A: 0.1657397449016571\n",
            "epoch: 45000, train_error(A): 0.00010246913734590635, test_error(B): 0.16627861559391022, B-A: 0.16617614030838013\n",
            "epoch: 45100, train_error(A): 0.00045927322935312986, test_error(B): 0.16634900867938995, B-A: 0.16588973999023438\n",
            "epoch: 45200, train_error(A): 0.0001236148236785084, test_error(B): 0.16641007363796234, B-A: 0.16628645360469818\n",
            "epoch: 45300, train_error(A): 0.0001004767109407112, test_error(B): 0.16678328812122345, B-A: 0.16668280959129333\n",
            "epoch: 45400, train_error(A): 0.000840958149638027, test_error(B): 0.16643601655960083, B-A: 0.16559505462646484\n",
            "epoch: 45500, train_error(A): 0.00014735950389876962, test_error(B): 0.16651776432991028, B-A: 0.16637040674686432\n",
            "epoch: 45600, train_error(A): 0.0001289359643124044, test_error(B): 0.16615886986255646, B-A: 0.1660299301147461\n",
            "epoch: 45700, train_error(A): 0.0008983125444501638, test_error(B): 0.16680200397968292, B-A: 0.16590368747711182\n",
            "epoch: 45800, train_error(A): 0.0006281365640461445, test_error(B): 0.16690313816070557, B-A: 0.1662749946117401\n",
            "epoch: 45900, train_error(A): 0.0009893861133605242, test_error(B): 0.16590765118598938, B-A: 0.16491825878620148\n",
            "epoch: 46000, train_error(A): 0.001479079481214285, test_error(B): 0.16612611711025238, B-A: 0.16464704275131226\n",
            "epoch: 46100, train_error(A): 0.00046586510143242776, test_error(B): 0.16655650734901428, B-A: 0.16609063744544983\n",
            "epoch: 46200, train_error(A): 0.0018106817733496428, test_error(B): 0.16796888411045074, B-A: 0.16615819931030273\n",
            "epoch: 46300, train_error(A): 0.0004350438539404422, test_error(B): 0.16755715012550354, B-A: 0.16712211072444916\n",
            "epoch: 46400, train_error(A): 0.0002829576551448554, test_error(B): 0.1671961098909378, B-A: 0.16691315174102783\n",
            "epoch: 46500, train_error(A): 0.0011844747932627797, test_error(B): 0.16638325154781342, B-A: 0.16519877314567566\n",
            "epoch: 46600, train_error(A): 0.0004640179395209998, test_error(B): 0.167313352227211, B-A: 0.16684933006763458\n",
            "epoch: 46700, train_error(A): 0.00039537210250273347, test_error(B): 0.16757169365882874, B-A: 0.16717632114887238\n",
            "epoch: 46800, train_error(A): 0.0010214087087661028, test_error(B): 0.16713620722293854, B-A: 0.16611479222774506\n",
            "epoch: 46900, train_error(A): 0.001318242633715272, test_error(B): 0.1668245792388916, B-A: 0.16550633311271667\n",
            "epoch: 47000, train_error(A): 0.0006093287956900895, test_error(B): 0.16735439002513885, B-A: 0.16674506664276123\n",
            "epoch: 47100, train_error(A): 0.0014620369765907526, test_error(B): 0.16714072227478027, B-A: 0.16567867994308472\n",
            "epoch: 47200, train_error(A): 0.0005748256808146834, test_error(B): 0.1672920286655426, B-A: 0.16671720147132874\n",
            "epoch: 47300, train_error(A): 0.00038694695103913546, test_error(B): 0.16753843426704407, B-A: 0.16715148091316223\n",
            "epoch: 47400, train_error(A): 0.0017978682881221175, test_error(B): 0.16663813591003418, B-A: 0.16484026610851288\n",
            "epoch: 47500, train_error(A): 0.0007070451974868774, test_error(B): 0.16790184378623962, B-A: 0.16719479858875275\n",
            "epoch: 47600, train_error(A): 0.0010115933837369084, test_error(B): 0.16829189658164978, B-A: 0.16728030145168304\n",
            "epoch: 47700, train_error(A): 0.0003342500713188201, test_error(B): 0.16768279671669006, B-A: 0.16734854876995087\n",
            "epoch: 47800, train_error(A): 0.0004992897156625986, test_error(B): 0.16743159294128418, B-A: 0.16693229973316193\n",
            "epoch: 47900, train_error(A): 0.0008933154167607427, test_error(B): 0.167719766497612, B-A: 0.16682645678520203\n",
            "epoch: 48000, train_error(A): 0.001295246067456901, test_error(B): 0.16719409823417664, B-A: 0.165898859500885\n",
            "epoch: 48100, train_error(A): 0.0015911463415250182, test_error(B): 0.1682116687297821, B-A: 0.16662052273750305\n",
            "epoch: 48200, train_error(A): 0.0002781246439553797, test_error(B): 0.16720734536647797, B-A: 0.1669292151927948\n",
            "epoch: 48300, train_error(A): 4.680027632275596e-05, test_error(B): 0.16753578186035156, B-A: 0.1674889773130417\n",
            "epoch: 48400, train_error(A): 0.00012099522427888587, test_error(B): 0.16762253642082214, B-A: 0.1675015389919281\n",
            "epoch: 48500, train_error(A): 0.0007348540239036083, test_error(B): 0.16710825264453888, B-A: 0.16637340188026428\n",
            "epoch: 48600, train_error(A): 0.0009375218069180846, test_error(B): 0.16808505356311798, B-A: 0.16714753210544586\n",
            "epoch: 48700, train_error(A): 0.0002153807581635192, test_error(B): 0.16759555041790009, B-A: 0.1673801690340042\n",
            "epoch: 48800, train_error(A): 0.0017480227397754788, test_error(B): 0.1686348170042038, B-A: 0.16688679158687592\n",
            "epoch: 48900, train_error(A): 0.00016855483409017324, test_error(B): 0.16776783764362335, B-A: 0.16759927570819855\n",
            "epoch: 49000, train_error(A): 0.0004637039382942021, test_error(B): 0.1680324673652649, B-A: 0.16756875813007355\n",
            "epoch: 49100, train_error(A): 0.0009879085700958967, test_error(B): 0.16717800498008728, B-A: 0.16619010269641876\n",
            "epoch: 49200, train_error(A): 0.0005908292951062322, test_error(B): 0.16758951544761658, B-A: 0.16699868440628052\n",
            "epoch: 49300, train_error(A): 0.0014753601280972362, test_error(B): 0.16921663284301758, B-A: 0.16774126887321472\n",
            "epoch: 49400, train_error(A): 0.0005363075179047883, test_error(B): 0.16741028428077698, B-A: 0.1668739765882492\n",
            "epoch: 49500, train_error(A): 0.00032894042669795454, test_error(B): 0.16833031177520752, B-A: 0.16800136864185333\n",
            "epoch: 49600, train_error(A): 0.0016987097915261984, test_error(B): 0.16733431816101074, B-A: 0.1656356155872345\n",
            "epoch: 49700, train_error(A): 0.0011646314524114132, test_error(B): 0.1685304492712021, B-A: 0.16736581921577454\n",
            "epoch: 49800, train_error(A): 0.0010406223591417074, test_error(B): 0.16853955388069153, B-A: 0.16749893128871918\n",
            "epoch: 49900, train_error(A): 0.0007193525671027601, test_error(B): 0.16809488832950592, B-A: 0.16737553477287292\n",
            "epoch: 50000, train_error(A): 0.0015188422985374928, test_error(B): 0.16827678680419922, B-A: 0.16675794124603271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnK6aiKY9hm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "e46c1a92-03c4-4818-ce88-b0153ff6af86"
      },
      "source": [
        "end_time = datetime.datetime.now() # 종료시간을 기록한다\n",
        "elapsed_time = end_time - start_time # 경과시간을 구한다\n",
        "print('elapsed_time:',elapsed_time)\n",
        "print('elapsed_time per epoch:',elapsed_time/epoch_num)\n",
        " \n",
        " \n",
        "# 하이퍼파라미터 출력\n",
        "print('input_data_column_cnt:', input_data_colums_count)\n",
        "print('output_data_column_cnt:', output_data_colums_count)\n",
        " \n",
        "print('seq_length:', seq_length)\n",
        "print('rnn_cell_hidden_dim:', rnn_cell_hidden_dim)\n",
        "print('forget_bias:', forget_bias)\n",
        "print('num_stacked_layers:', num_stacked_layers)\n",
        "print('keep_prob:', keep_prob)\n",
        " \n",
        "print('epoch_num:', epoch_num)\n",
        "print('learning_rate:', learning_rate)\n",
        " \n",
        "print('train_error:', train_error_summary[-1])\n",
        "print('test_error:', test_error_summary[-1])\n",
        "print('min_test_error:', np.min(test_error_summary))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "elapsed_time: 0:00:11.755077\n",
            "elapsed_time per epoch: 0:00:00.023510\n",
            "input_data_column_cnt: 13\n",
            "output_data_column_cnt: 1\n",
            "seq_length: 16\n",
            "rnn_cell_hidden_dim: 20\n",
            "forget_bias: 1.0\n",
            "num_stacked_layers: 1\n",
            "keep_prob: 1.0\n",
            "epoch_num: 500\n",
            "learning_rate: 0.01\n",
            "train_error: 0.04625409\n",
            "test_error: 0.15960394\n",
            "min_test_error: 0.13006368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFlACTrW-NMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "9dc4b80e-3934-4929-c8b6-b264cdd32a72"
      },
      "source": [
        "# 결과 그래프 출력\n",
        "plt.figure(1)\n",
        "plt.plot(train_error_summary, 'gold')\n",
        "plt.plot(test_error_summary, 'b')\n",
        "plt.xlabel('Epoch(x100)')\n",
        "plt.ylabel('Root Mean Square Error')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Root Mean Square Error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0Z/6JUs4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzC2zjXP-PAm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "e297e594-c7c9-4e3b-941c-ad5d426a515b"
      },
      "source": [
        "# sequence length만큼의 가장 최근 데이터를 슬라이싱한다\n",
        "recent_data = np.array([x[len(x)-seq_length : ]])\n",
        "print(\"recent_data.shape:\", recent_data.shape)\n",
        "print(\"recent_data:\", recent_data)\n",
        " \n",
        "# 내년 생산량을 예측한다.\n",
        "test_predict = sess.run(hypothesis, feed_dict={X: recent_data})\n",
        " \n",
        "print(\"test_predict\", test_predict[0])\n",
        "test_predict = reverse_min_max_scaling(product_num,test_predict) # 생산량 데이터를 역정규화\n",
        "print(\"내년 생산량 : \", test_predict[0]) # 예측한 생산량을 출력"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recent_data.shape: (1, 16, 13)\n",
            "recent_data: [[[0.49315001 0.51666581 0.44680756 0.41747532 0.47727218 0.24999961\n",
            "   0.78124919 0.82926728 0.83561529 0.1624998  0.09420283 0.08108101\n",
            "   0.44040906]\n",
            "  [0.61643751 0.91666514 0.51063721 0.69902845 0.9204535  0.60937405\n",
            "   0.52083279 0.78048685 0.49315001 0.18749977 0.04347823 0.09009001\n",
            "   0.47166205]\n",
            "  [0.58904029 0.68333219 0.68084962 0.66019353 0.76136277 0.7031239\n",
            "   0.635416   0.70731621 0.71232779 0.1624998  0.04347823 0.09909901\n",
            "   0.43954889]\n",
            "  [0.43835556 0.39999933 0.29787171 0.68931972 0.74999915 0.67187395\n",
            "   0.3541663  0.341463   0.246575   0.1624998  0.04347823 0.09009001\n",
            "   0.30526618]\n",
            "  [0.63013612 0.74999875 0.68084962 0.56310625 0.70454465 0.51562419\n",
            "   0.71874925 0.84146239 0.80821807 0.21249973 0.07246372 0.08108101\n",
            "   0.15769856]\n",
            "  [0.42465695 0.48333253 0.38297791 0.50485388 0.64772654 0.43749932\n",
            "   0.51041613 0.53658471 0.53424584 0.17499978 0.07246372 0.07207201\n",
            "   0.4710886 ]\n",
            "  [0.73972501 0.91666514 0.89361512 0.67961099 0.77272639 0.7031239\n",
            "   0.73958256 0.95121835 0.99999863 0.24999969 0.08695646 0.018018\n",
            "   0.42559495]\n",
            "  [0.69862918 0.79999867 0.42553101 0.76698955 0.82954451 0.54687415\n",
            "   0.58333273 0.71951132 0.54794445 0.31249961 0.12318832 0.09009001\n",
            "   0.45436299]\n",
            "  [0.68493057 0.79999867 0.72340272 0.67961099 0.78409002 0.65624897\n",
            "   0.77083253 0.87804771 0.86301252 0.2374997  0.07246372 0.05405401\n",
            "   0.40581095]\n",
            "  [0.79451946 0.74999875 0.36170136 0.93203793 0.98863524 0.73437385\n",
            "   0.64583266 0.53658471 0.32876667 0.28749964 0.16666655 0.07207201\n",
            "   0.58358023]\n",
            "  [0.49315001 0.51666581 0.44680756 0.41747532 0.47727218 0.24999961\n",
            "   0.78124919 0.82926728 0.83561529 0.1624998  0.09420283 0.08108101\n",
            "   0.48695403]\n",
            "  [0.36986251 0.43333261 0.27659516 0.26213567 0.26136334 0.\n",
            "   0.65624932 0.79268196 0.73972501 0.18749977 0.05797097 0.08108101\n",
            "   0.41202332]\n",
            "  [0.36986251 0.46666589 0.25531861 0.28155312 0.31818146 0.01562498\n",
            "   0.635416   0.74390153 0.69862918 0.18749977 0.11594194 0.045045\n",
            "   0.51008315]\n",
            "  [0.53424584 0.56666572 0.42553101 0.46601897 0.51136306 0.37499941\n",
            "   0.7083326  0.74390153 0.63013612 0.22499972 0.04347823 0.07207201\n",
            "   0.44776833]\n",
            "  [0.71232779 0.81666531 0.80850892 0.58252371 0.64772654 0.54687415\n",
            "   0.76041587 0.93902325 0.97260141 0.2374997  0.0507246  0.027027\n",
            "   0.43821084]\n",
            "  [0.76712224 0.78333203 0.55319031 0.79611573 0.84090814 0.640624\n",
            "   0.7083326  0.6951211  0.6027389  0.6374992  0.21739115 0.12612601\n",
            "   0.45512759]]]\n",
            "test_predict [0.7199449]\n",
            "내년 생산량 :  [7532.783]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-5tf5nb-RBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}